{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id  movie_id_ml  rating     rating_timestamp  \\\n",
      "0          186          302       3  1998-04-04 19:22:22   \n",
      "1          186         1042       5  1997-11-08 21:13:52   \n",
      "2          186           98       5  1998-04-04 19:57:39   \n",
      "3          186          327       3  1998-04-04 19:23:26   \n",
      "4          186          332       4  1998-04-04 19:56:15   \n",
      "...        ...          ...     ...                  ...   \n",
      "79784      358         1149       3  1998-03-30 15:00:43   \n",
      "79785      358          584       4  1998-03-30 14:58:33   \n",
      "79786      358          918       1  1998-04-16 12:54:14   \n",
      "79787      358          896       4  1998-03-30 14:44:37   \n",
      "79788      358         1159       5  1998-03-30 14:53:37   \n",
      "\n",
      "                          title  release  \\\n",
      "0             l.a. confidential     1997   \n",
      "1                    just cause     1995   \n",
      "2      the silence of the lambs     1991   \n",
      "3                      cop land     1997   \n",
      "4                kiss the girls     1997   \n",
      "...                         ...      ...   \n",
      "79784                 walkabout     1971   \n",
      "79785         the secret garden     1993   \n",
      "79786            city of angels     1998   \n",
      "79787       the sweet hereafter     1997   \n",
      "79788                   stalker     1979   \n",
      "\n",
      "                                                     url  unknown  action  \\\n",
      "0      http://us.imdb.com/M/title-exact?L%2EA%2E+Conf...        0       0   \n",
      "1      http://us.imdb.com/M/title-exact?Just%20Cause%...        0       0   \n",
      "2      http://us.imdb.com/M/title-exact?Silence%20of%...        0       0   \n",
      "3       http://us.imdb.com/M/title-exact?Cop+Land+(1997)        0       0   \n",
      "4      http://us.imdb.com/M/title-exact?Kiss+the+Girl...        0       0   \n",
      "...                                                  ...      ...     ...   \n",
      "79784  http://us.imdb.com/M/title-exact?Walkabout%20(...        0       0   \n",
      "79785  http://us.imdb.com/M/title-exact?Secret%20Gard...        0       0   \n",
      "79786     http://us.imdb.com/Title?City+of+Angels+(1998)        0       0   \n",
      "79787  http://us.imdb.com/M/title-exact?Sweet+Hereaft...        0       0   \n",
      "79788  http://us.imdb.com/M/title-exact?Stalker%20(1979)        0       0   \n",
      "\n",
      "       adventure  ...                                            keyword  \\\n",
      "0              0  ...  ['rainstorm', 'face-slap', 'closeted-homosexua...   \n",
      "1              0  ...  ['car-chase', 'african-american', '1990s', 'ba...   \n",
      "2              0  ...  ['good-versus-evil', 'gore', '1990s', 'flashba...   \n",
      "3              0  ...  ['marriage', 'strip-club', 'gore', 'african-am...   \n",
      "4              0  ...  ['waterfall', 'gore', 'based-on-novel', 'chase...   \n",
      "...          ...  ...                                                ...   \n",
      "79784          0  ...  ['father-son-relationship', 'mother-son-relati...   \n",
      "79785          0  ...  ['title-directed-by-female', 'father-son-relat...   \n",
      "79786          0  ...  ['remake', 'death', 'los-angeles-california', ...   \n",
      "79787          0  ...  ['father-son-relationship', 'mother-son-relati...   \n",
      "79788          0  ...  ['marriage', 'fog', 'waterfall', 'father-daugh...   \n",
      "\n",
      "                                                    cast  \\\n",
      "0      [{\"cast_id\": 69299, \"person_id\": 10906, \"cast_...   \n",
      "1      [{\"cast_id\": 798327, \"person_id\": 112106, \"cas...   \n",
      "2      [{\"cast_id\": 19315, \"person_id\": 3563, \"cast_n...   \n",
      "3      [{\"cast_id\": 216053, \"person_id\": 33589, \"cast...   \n",
      "4      [{\"cast_id\": 91421, \"person_id\": 14758, \"cast_...   \n",
      "...                                                  ...   \n",
      "79784  [{\"cast_id\": 1837122, \"person_id\": 247140, \"ca...   \n",
      "79785  [{\"cast_id\": 584717, \"person_id\": 83235, \"cast...   \n",
      "79786  [{\"cast_id\": 478478, \"person_id\": 68865, \"cast...   \n",
      "79787  [{\"cast_id\": 590972, \"person_id\": 84026, \"cast...   \n",
      "79788  [{\"cast_id\": 4488068, \"person_id\": 600067, \"ca...   \n",
      "\n",
      "                                                 company  user_age  \\\n",
      "0      [{\"company_id\": 6, \"name\": \"Columbia Broadcast...        39   \n",
      "1      [{\"company_id\": 19, \"name\": \"National Broadcas...        39   \n",
      "2      [{\"company_id\": 6, \"name\": \"Columbia Broadcast...        39   \n",
      "3      [{\"company_id\": 1431, \"name\": \"Buena Vista Pic...        39   \n",
      "4      [{\"company_id\": 19, \"name\": \"National Broadcas...        39   \n",
      "...                                                  ...       ...   \n",
      "79784  [{\"company_id\": 1705, \"name\": \"Criterion Colle...        40   \n",
      "79785  [{\"company_id\": 34, \"name\": \"Warner Home Video...        40   \n",
      "79786  [{\"company_id\": 6, \"name\": \"Columbia Broadcast...        40   \n",
      "79787  [{\"company_id\": 521, \"name\": \"Argentina Video ...        40   \n",
      "79788  [{\"company_id\": 12507, \"name\": \"Alta Films\", \"...        40   \n",
      "\n",
      "       user_gender  user_occupation  user_zipcode     tconst     nconst  \\\n",
      "0                F        executive         00000  tt0119488  nm0000436   \n",
      "1                F        executive         00000  tt0113501  nm0322865   \n",
      "2                F        executive         00000  tt0102926  nm0001129   \n",
      "3                F        executive         00000  tt0118887  nm0003506   \n",
      "4                F        executive         00000  tt0119468  nm0001219   \n",
      "...            ...              ...           ...        ...        ...   \n",
      "79784            M         educator         10022  tt0067959  nm0001676   \n",
      "79785            M         educator         10022  tt1372606  nm0144482   \n",
      "79786            M         educator         10022  tt0120632  nm0797869   \n",
      "79787            M         educator         10022  tt0120255  nm0000382   \n",
      "79788            M         educator         10022  tt0079944  nm0001789   \n",
      "\n",
      "               director  \n",
      "0         Curtis Hanson  \n",
      "1         Arne Glimcher  \n",
      "2        Jonathan Demme  \n",
      "3         James Mangold  \n",
      "4           Gary Fleder  \n",
      "...                 ...  \n",
      "79784      Nicolas Roeg  \n",
      "79785    Xavier Castano  \n",
      "79786   Brad Silberling  \n",
      "79787       Atom Egoyan  \n",
      "79788  Andrei Tarkovsky  \n",
      "\n",
      "[79675 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Load the new datasets\n",
    "#df_movies_all = pd.read_csv(\"data_analysis/movies.txt\", sep=',')\n",
    "#df_cast_people = pd.read_csv(\"data_analysis/cast.txt\", sep=',')\n",
    "#df_movie_companies = pd.read_csv(\"data_analysis/companies.txt\", sep=',')\n",
    "#df_ratings = pd.read_csv(\"data_analysis/ratings.txt\", sep=',')\n",
    "#df_users = pd.read_csv(\"data_analysis/users.txt\", sep=',')\n",
    "#movies_cast_company = pd.read_csv(\"data_analysis/movies_cast_company.txt\", sep=',')\n",
    "\n",
    "final_dataset = pd.read_csv('data_analysis/final_dataset.csv')\n",
    "\n",
    "\n",
    "# Filter users with more than 200 interactions\n",
    "user_interactions = final_dataset.groupby('user_id').size()\n",
    "user_indexes = user_interactions[user_interactions > 200].index\n",
    "filtered_ratings = final_dataset[final_dataset.user_id.isin(user_indexes)]\n",
    "\n",
    "# Ensure movie filtering matches the filtered ratings\n",
    "filtered_movies = final_dataset[final_dataset['movie_id_ml'].isin(filtered_ratings['movie_id_ml'])]\n",
    "\n",
    "# Drop NaN values and unused columns for the movie dataset\n",
    "filtered_movies = filtered_movies.dropna(axis=1)\n",
    "\n",
    "\n",
    "print(filtered_movies)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Ratings Columns: Index(['user_id', 'movie_id_ml', 'rating', 'rating_timestamp', 'title',\n",
      "       'release', 'url', 'unknown', 'action', 'adventure', 'animation',\n",
      "       'childrens', 'comedy', 'crime', 'documentary', 'drama', 'fantasy',\n",
      "       'noir', 'horror', 'musical', 'mystery', 'romance', 'scifi', 'thriller',\n",
      "       'war', 'western', 'movie_id', 'keyword', 'cast', 'company', 'user_age',\n",
      "       'user_gender', 'user_occupation', 'user_zipcode', 'tconst', 'nconst',\n",
      "       'director'],\n",
      "      dtype='object')\n",
      "User Movies Columns: Index(['user_id', 'movie_id_ml', 'rating', 'rating_timestamp', 'title',\n",
      "       'release', 'url', 'unknown', 'action', 'adventure', 'animation',\n",
      "       'childrens', 'comedy', 'crime', 'documentary', 'drama', 'fantasy',\n",
      "       'noir', 'horror', 'musical', 'mystery', 'romance', 'scifi', 'thriller',\n",
      "       'war', 'western', 'movie_id', 'keyword', 'cast', 'company', 'user_age',\n",
      "       'user_gender', 'user_occupation', 'user_zipcode', 'tconst', 'nconst',\n",
      "       'director'],\n",
      "      dtype='object')\n",
      "Merged User Data Columns: Index(['user_id_movie', 'movie_id_ml', 'rating_movie',\n",
      "       'rating_timestamp_movie', 'title_movie', 'release_movie', 'url_movie',\n",
      "       'unknown_movie', 'action_movie', 'adventure_movie', 'animation_movie',\n",
      "       'childrens_movie', 'comedy_movie', 'crime_movie', 'documentary_movie',\n",
      "       'drama_movie', 'fantasy_movie', 'noir_movie', 'horror_movie',\n",
      "       'musical_movie', 'mystery_movie', 'romance_movie', 'scifi_movie',\n",
      "       'thriller_movie', 'war_movie', 'western_movie', 'movie_id_movie',\n",
      "       'keyword_movie', 'cast_movie', 'company_movie', 'user_age_movie',\n",
      "       'user_gender_movie', 'user_occupation_movie', 'user_zipcode_movie',\n",
      "       'tconst_movie', 'nconst_movie', 'director_movie', 'user_id_rating',\n",
      "       'rating_rating', 'rating_timestamp_rating', 'title_rating',\n",
      "       'release_rating', 'url_rating', 'unknown_rating', 'action_rating',\n",
      "       'adventure_rating', 'animation_rating', 'childrens_rating',\n",
      "       'comedy_rating', 'crime_rating', 'documentary_rating', 'drama_rating',\n",
      "       'fantasy_rating', 'noir_rating', 'horror_rating', 'musical_rating',\n",
      "       'mystery_rating', 'romance_rating', 'scifi_rating', 'thriller_rating',\n",
      "       'war_rating', 'western_rating', 'movie_id_rating', 'keyword_rating',\n",
      "       'cast_rating', 'company_rating', 'user_age_rating',\n",
      "       'user_gender_rating', 'user_occupation_rating', 'user_zipcode_rating',\n",
      "       'tconst_rating', 'nconst_rating', 'director_rating'],\n",
      "      dtype='object')\n",
      "X_train shape: (1400, 5190)\n",
      "y_train shape: (1400,)\n",
      "X_test shape: (600, 5190)\n",
      "y_test shape: (600,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Select a random user for testing\n",
    "test_user = random.choice(filtered_ratings.user_id.unique())\n",
    "\n",
    "# Function to prepare training and testing data for a specific user\n",
    "def get_data_for_user(filtered_ratings, filtered_movies, user_id, sample_size=2000):\n",
    "    \"\"\"\n",
    "    Prepare training and testing data for a specific user, with optional data sampling.\n",
    "    \"\"\"\n",
    "    # Filter ratings for the selected user\n",
    "    user_ratings = filtered_ratings[filtered_ratings['user_id'] == user_id]\n",
    "    print(f\"User Ratings Columns: {user_ratings.columns}\")  # Debug: Check columns in user_ratings\n",
    "\n",
    "    # Filter movies rated by the selected user\n",
    "    user_movies = filtered_movies[filtered_movies['movie_id_ml'].isin(user_ratings['movie_id_ml'])]\n",
    "    print(f\"User Movies Columns: {user_movies.columns}\")  # Debug: Check columns in user_movies\n",
    "\n",
    "    # Merge user ratings with movie data\n",
    "    user_data = user_movies.merge(\n",
    "        user_ratings,\n",
    "        on='movie_id_ml',  # Merge based on the movie ID\n",
    "        suffixes=('_movie', '_rating')\n",
    "    )\n",
    "    print(f\"Merged User Data Columns: {user_data.columns}\")  # Debug: Check columns after merging\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    if 'user_id_movie' in user_data.columns:\n",
    "        user_data = user_data.drop(['user_id_movie'], axis=1)\n",
    "    if 'rating_timestamp_movie' in user_data.columns:\n",
    "        user_data = user_data.drop(['rating_timestamp_movie'], axis=1)\n",
    "\n",
    "    # Ensure the correct column name for 'rating' is used\n",
    "    if 'rating_rating' in user_data.columns:\n",
    "        rating_column = 'rating_rating'\n",
    "    else:\n",
    "        raise KeyError(\"'rating' column not found in merged user_data.\")\n",
    "\n",
    "    # Separate features (X) and target (y)\n",
    "    X = user_data.drop(rating_column, axis=1)\n",
    "    y = user_data[rating_column]\n",
    "\n",
    "    # Handle non-numeric columns using one-hot encoding\n",
    "    X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "    # Randomly sample the data, limiting it to the specified sample size\n",
    "    sample_indices = random.sample(range(X.shape[0]), min(sample_size, X.shape[0]))\n",
    "    X_sampled = X.iloc[sample_indices]\n",
    "    y_sampled = y.iloc[sample_indices]\n",
    "\n",
    "    # Split the sampled data into training and testing sets\n",
    "    return train_test_split(X_sampled, y_sampled, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "# Generate training and testing datasets for the selected user\n",
    "try:\n",
    "    X_train, X_test, y_train, y_test = get_data_for_user(filtered_ratings, filtered_movies, test_user)\n",
    "\n",
    "    # Output shapes of the resulting datasets\n",
    "    print(f\"X_train shape: {X_train.shape}\")\n",
    "    print(f\"y_train shape: {y_train.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}\")\n",
    "    print(f\"y_test shape: {y_test.shape}\")\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X shape: (30183, 4553), y shape: (30183,)\n",
      "After splitting: X_train shape: (30183, 4553), y_train shape: (30183,)\n",
      "After adjustments: X_train shape: (30183, 4553), y_train_adjusted shape: (298,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original X shape: {X_train.shape}, y shape: {y_train.shape}\")\n",
    "print(f\"After splitting: X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"After adjustments: X_train shape: {X_train.shape}, y_train_adjusted shape: {y_train_adjusted.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LogisticRegression...\n",
      "Best model for LogisticRegression: LogisticRegression(C=0.1, max_iter=1000, solver='liblinear'), Score: 0.962\n",
      "Evaluating RandomForest...\n",
      "Best model for RandomForest: RandomForestClassifier(), Score: 0.967\n",
      "Evaluating DecisionTree...\n",
      "Best model for DecisionTree: DecisionTreeClassifier(), Score: 0.96\n",
      "Evaluating MLPClassifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:412: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.array(param_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model for MLPClassifier: MLPClassifier(hidden_layer_sizes=(150,), max_iter=1000, random_state=42), Score: 0.9710000000000001\n",
      "Evaluating SVD...\n",
      "Best RMSE for SVD: 0.8981705712568898, Params: {'n_factors': 150, 'n_epochs': 50, 'lr_all': 0.01}\n",
      "Evaluating NMF...\n",
      "Best RMSE for NMF: 0.9194070624988008, Params: {'n_factors': 20, 'n_epochs': 20}\n",
      "Evaluating XGBoost...\n",
      "Best model for XGBoost: XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, objective='multi:softprob', ...), Score: 0.96\n",
      "\n",
      "Best Models and Scores:\n",
      "LogisticRegression: Best Accuracy = 0.962, Best Estimator = LogisticRegression(C=0.1, max_iter=1000, solver='liblinear')\n",
      "RandomForest: Best Accuracy = 0.967, Best Estimator = RandomForestClassifier()\n",
      "DecisionTree: Best Accuracy = 0.96, Best Estimator = DecisionTreeClassifier()\n",
      "MLPClassifier: Best Accuracy = 0.9710000000000001, Best Estimator = MLPClassifier(hidden_layer_sizes=(150,), max_iter=1000, random_state=42)\n",
      "SVD: Best RMSE = 0.8981705712568898, Params = <surprise.prediction_algorithms.matrix_factorization.SVD object at 0x00000161C0DCD990>\n",
      "NMF: Best RMSE = 0.9194070624988008, Params = <surprise.prediction_algorithms.matrix_factorization.NMF object at 0x00000161C0D308D0>\n",
      "XGBoost: Best Accuracy = 0.96, Best Estimator = XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, objective='multi:softprob', ...)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from surprise import SVD, NMF, Dataset, Reader\n",
    "from surprise.model_selection import GridSearchCV as SurpriseGridSearch, cross_validate\n",
    "from xgboost import XGBClassifier\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#X_train, X_test, y_train, y_test = get_data_for_user(filtered_ratings, filtered_movies, test_user)\n",
    "reader = Reader(rating_scale=(1, 5))  # Adjust the rating scale if needed\n",
    "\n",
    "# Convert the DataFrame into a Surprise dataset\n",
    "data = Dataset.load_from_df(filtered_ratings[['user_id', 'movie_id', 'rating']], reader)\n",
    "\n",
    "param_grid = {\n",
    "    'LogisticRegression': {\n",
    "        'model': LogisticRegression(),\n",
    "        'params': {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'solver': ['liblinear', 'lbfgs'],\n",
    "            'max_iter': [1000]\n",
    "        }\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': [10, 50, 100],\n",
    "            'max_depth': [None, 10, 20]\n",
    "        }\n",
    "    },\n",
    "    'DecisionTree': {\n",
    "        'model': DecisionTreeClassifier(),\n",
    "        'params': {\n",
    "            'max_depth': [None, 10, 20],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        }\n",
    "    },\n",
    "    'MLPClassifier': {\n",
    "        'model': MLPClassifier(max_iter=1000, random_state=42),\n",
    "        'params': {\n",
    "            'hidden_layer_sizes': [(100,), (100, 50), (150,), (150, 75)],\n",
    "            'activation': ['relu'],\n",
    "            'solver': ['adam'],\n",
    "            'alpha': [0.0001, 0.001, 0.01]\n",
    "        }\n",
    "    },\n",
    "    'SVD': {\n",
    "        'model': SVD,\n",
    "        'params': {\n",
    "            'n_factors': [50, 100, 150],\n",
    "            'n_epochs': [20, 50],\n",
    "            'lr_all': [0.005, 0.01]\n",
    "        }\n",
    "    },\n",
    "    'NMF': {\n",
    "        'model': NMF,\n",
    "        'params': {\n",
    "            'n_factors': [10, 20],\n",
    "            'n_epochs': [20, 50]\n",
    "        }\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': XGBClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': [50, 100],\n",
    "            'learning_rate': [0.1, 0.01],\n",
    "            'max_depth': [3, 5, 10]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Perform grid search for Scikit-learn and Surprise models\n",
    "best_models = {}\n",
    "for model_name, model_info in param_grid.items():\n",
    "    model = model_info['model']\n",
    "    params = model_info['params']\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    \n",
    "    if model_name in ['SVD', 'NMF']:\n",
    "        # Use Surprise's GridSearchCV for hyperparameter tuning\n",
    "        gs = SurpriseGridSearch(param_grid=params, measures=['rmse'], cv=5, algo_class=SVD)\n",
    "        gs.fit(data)\n",
    "        best_params = gs.best_params['rmse']\n",
    "        best_score = gs.best_score['rmse']\n",
    "        best_models[model_name] = (model(**best_params), best_score)\n",
    "        print(f\"Best RMSE for {model_name}: {best_score}, Params: {best_params}\")\n",
    "    \n",
    "    else:\n",
    "        # Scale the data before fitting the models that require scaling (e.g., Logistic Regression)\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_train_scaled_subset = X_train_scaled[:1000]  # Use the first 1000 samples as a subset\n",
    "        y_train_subset = y_train[:1000]\n",
    "        label_encoder = LabelEncoder()\n",
    "        y_train_subset_encoded = label_encoder.fit_transform(y_train_subset)\n",
    "\n",
    "        # Perform Grid Search for Scikit-learn compatible models\n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=params, cv=5, scoring='accuracy', n_jobs=2)\n",
    "        grid_search.fit(X_train_scaled_subset, y_train_subset_encoded)\n",
    "        best_models[model_name] = (grid_search.best_estimator_, grid_search.best_score_)\n",
    "        print(f\"Best model for {model_name}: {grid_search.best_estimator_}, Score: {grid_search.best_score_}\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nBest Models and Scores:\")\n",
    "for model_name, model_info in best_models.items():\n",
    "    if model_name in ['SVD', 'NMF']:\n",
    "        # For SVD and NMF, display the best RMSE and the best hyperparameters directly\n",
    "        print(f\"{model_name}: Best RMSE = {model_info[1]}, Params = {model_info[0]}\")\n",
    "    else:\n",
    "        # For other models (like RandomForest, MLPClassifier, etc.), display accuracy and best estimator\n",
    "        print(f\"{model_name}: Best Accuracy = {model_info[1]}, Best Estimator = {model_info[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['movie_id_ml', 'title', 'release', 'url', 'unknown', 'action',\n",
      "       'adventure', 'animation', 'childrens', 'comedy', 'crime', 'documentary',\n",
      "       'drama', 'fantasy', 'noir', 'horror', 'musical', 'mystery', 'romance',\n",
      "       'scifi', 'thriller', 'war', 'western', 'movie_id', 'keyword', 'cast',\n",
      "       'company'],\n",
      "      dtype='object')\n",
      "Index(['user_id', 'movie_id_ml', 'rating', 'rating_timestamp'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(movies_cast_company.columns)\n",
    "print(df_ratings.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
